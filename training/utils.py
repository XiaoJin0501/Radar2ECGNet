# training/utils.py

import torch
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from typing import Dict
import os # <--- åœ¨è¿™é‡Œæ·»åŠ è¿™ä¸€è¡Œ

def plot_waveform_comparison(
    model: torch.nn.Module, 
    dataloader: DataLoader, 
    epoch: int, 
    device: torch.device, 
    num_samples: int = 5
) -> plt.Figure:
    """
    åˆ›å»ºä¸€ä¸ªåŒ…å«çœŸå®žæ³¢å½¢å’Œæ¨¡åž‹é‡å»ºæ³¢å½¢å¯¹æ¯”çš„ Matplotlib Figure å¯¹è±¡ã€‚
    
    Args:
        model: è¦è¯„ä¼°çš„æ¨¡åž‹.
        dataloader: æä¾›éªŒè¯æ•°æ®çš„ DataLoader.
        epoch: å½“å‰çš„ Epoch æ•°ï¼Œç”¨äºŽæ ‡é¢˜.
        device: 'cuda' æˆ– 'cpu'.
        num_samples: è¦ç»˜åˆ¶çš„æ ·æœ¬æ•°é‡.
        
    Returns:
        ä¸€ä¸ª Matplotlib Figure å¯¹è±¡ï¼Œå¯ä¾› TensorBoard è®°å½•.
    """
    model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
    
    # ä»Žæ•°æ®åŠ è½½å™¨ä¸­èŽ·å–ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®
    try:
        batch = next(iter(dataloader))
        ecg_true = batch['ecg'].to(device)
    except StopIteration:
        print("Warning: Dataloader is empty, cannot generate visualization.")
        return plt.figure() # è¿”å›žä¸€ä¸ªç©ºå›¾åƒ

    with torch.no_grad():
        # å‡è®¾æ¨¡åž‹è¾“å…¥æ˜¯ecgï¼Œå¯¹äºŽé›·è¾¾é¡¹ç›®ï¼Œå¯èƒ½æ˜¯ model(batch['radar'].to(device))
        # â†“â†“â†“ åœ¨è¿™é‡Œå¢žåŠ å’Œè®­ç»ƒ/éªŒè¯å‡½æ•°ä¸­ä¸€æ ·çš„ç»´åº¦è½¬æ¢ â†“â†“â†“
        ecg_true_model_input = ecg_true.transpose(1, 2)
        
        # å°†æ­£ç¡®å½¢çŠ¶çš„æ•°æ®é€å…¥æ¨¡åž‹
        ecg_pred, _ = model(ecg_true_model_input)
    
    # å°†Tensorè½¬åˆ°CPUå¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
    ecg_true_np = ecg_true.cpu().numpy()
    ecg_pred_np = ecg_pred.cpu().numpy()
    
    # ç¡®ä¿æˆ‘ä»¬ä¸ä¼šå°è¯•ç»˜åˆ¶æ¯”æ‰¹æ¬¡ä¸­æ›´å¤šçš„æ ·æœ¬
    actual_samples = min(num_samples, ecg_true.size(0))
    
    # åˆ›å»ºä¸€ä¸ªå¤§å›¾ï¼ŒåŒ…å« num_samples ä¸ªå­å›¾
    fig, axes = plt.subplots(actual_samples, 1, figsize=(15, 3 * actual_samples), squeeze=False)
    fig.suptitle(f'ECG Reconstruction - Epoch {epoch}', fontsize=16)

    for i in range(actual_samples):
        ax = axes[i, 0]
        ax.plot(ecg_true_np[i, 0, :], label='Ground Truth ECG', color='blue', linewidth=1.5)
        ax.plot(ecg_pred_np[i, 0, :], label='Reconstructed ECG', color='red', linestyle='--')
        ax.set_title(f'Sample {i+1}')
        ax.legend()
        ax.set_xlabel('Time Steps')
        ax.set_ylabel('Amplitude')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    
    model.train() # åˆ‡æ¢å›žè®­ç»ƒæ¨¡å¼
    
    return fig

class LossManager:
    """æŸå¤±ç®¡ç†å™¨ - ç”¨äºŽè·Ÿè¸ªå’Œè®°å½•æŸå¤±"""
    
    def __init__(self):
        self.reset()
        
    def reset(self):
        """é‡ç½®æŸå¤±è®°å½•"""
        self.losses = {}
        self.counts = {}
        
    def update(self, loss_dict: dict, batch_size: int = 1):
        """æ›´æ–°æŸå¤±è®°å½•"""
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                value = value.item()
                
            if key not in self.losses:
                self.losses[key] = 0.0
                self.counts[key] = 0
                
            self.losses[key] += value * batch_size
            self.counts[key] += batch_size
            
    def get_average_losses(self) -> dict:
        """èŽ·å–å¹³å‡æŸå¤±"""
        avg_losses = {}
        for key in self.losses:
            if self.counts[key] > 0:
                avg_losses[key] = self.losses[key] / self.counts[key]
            else:
                avg_losses[key] = 0.0
        return avg_losses
    
    def get_total_loss(self) -> float:
        """èŽ·å–æ€»æŸå¤±çš„å¹³å‡å€¼"""
        avg_losses = self.get_average_losses()
        return avg_losses.get('total', avg_losses.get('total_loss', 0.0))
    
    #åˆ›å»ºä¸€ä¸ªé€šç”¨çš„ä¿å­˜æ£€æŸ¥ç‚¹çš„å‡½æ•°ï¼Œæ–­ç‚¹ç»­è®­ (Resuming from a checkpoint)
def save_checkpoint(state: dict, is_best: bool, checkpoint_dir: str, experiment_name: str):
    """
    ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚
    
    Args:
        state: åŒ…å«æ¨¡åž‹ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œepochç­‰ä¿¡æ¯çš„å­—å…¸
               åº”è¯¥åŒ…å«ä»¥ä¸‹é”®: 'epoch', 'model_state_dict', 'optimizer_state_dict', 'best_val_loss'
        is_best: å½“å‰æ¨¡åž‹æ˜¯å¦æ˜¯éªŒè¯é›†ä¸Šæœ€ä¼˜çš„
        checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
        experiment_name: å®žéªŒåç§°ï¼Œç”¨äºŽæž„æˆæ–‡ä»¶å
    """
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # ä¿å­˜æœ€æ–°çš„æ£€æŸ¥ç‚¹ï¼Œç”¨äºŽæ–­ç‚¹ç»­è®­
    latest_path = os.path.join(checkpoint_dir, f"latest_{experiment_name}.pth")
    torch.save(state, latest_path)
    print(f"ðŸ’¾ å·²ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹: {latest_path}")
    
    # å¦‚æžœæ˜¯æœ€ä½³æ¨¡åž‹ï¼Œé¢å¤–ä¿å­˜æœ€ä½³æ¨¡åž‹ï¼ˆåªä¿å­˜æ¨¡åž‹æƒé‡ï¼Œç”¨äºŽæŽ¨ç†ï¼‰
    if is_best:
        best_path = os.path.join(checkpoint_dir, f"best_{experiment_name}.pth")
        torch.save(state['model'], best_path)
        print(f"âœ… å‘çŽ°æ›´ä¼˜æ¨¡åž‹ (Val Loss: {state['best_val_loss']:.4f})ï¼Œå·²ä¿å­˜è‡³: {best_path}")


def load_checkpoint(checkpoint_path: str, model: torch.nn.Module, optimizer: torch.optim.Optimizer = None):
    """
    ä»Žæ£€æŸ¥ç‚¹åŠ è½½æ¨¡åž‹å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚
    
    Args:
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        model: è¦åŠ è½½çŠ¶æ€çš„æ¨¡åž‹
        optimizer: è¦åŠ è½½çŠ¶æ€çš„ä¼˜åŒ–å™¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        tuple: (start_epoch, best_val_loss) å¦‚æžœæˆåŠŸåŠ è½½ï¼Œå¦åˆ™ (0, float('inf'))
    """
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return 0, float('inf')
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # åŠ è½½æ¨¡åž‹çŠ¶æ€
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"âœ… å·²åŠ è½½æ¨¡åž‹çŠ¶æ€ä»Ž: {checkpoint_path}")
        
        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå¦‚æžœæä¾›äº†ä¼˜åŒ–å™¨ï¼‰
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            print(f"âœ… å·²åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€")
        
        start_epoch = checkpoint.get('epoch', 0) + 1
        best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        
        print(f"ðŸ“Š å°†ä»Ž epoch {start_epoch} ç»§ç»­è®­ç»ƒï¼Œå½“å‰æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
        
        return start_epoch, best_val_loss
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        return 0, float('inf')

def plot_ce_prediction(
    self,
    model: torch.nn.Module, 
    dataloader: DataLoader, 
    epoch: int, 
    device: torch.device, 
    num_samples: int = 4
) -> plt.Figure:
    """
    å¯è§†åŒ–CEé¢„æµ‹å™¨çš„é¢„æµ‹ç»“æžœã€‚
    å®ƒä¼šå°†çœŸå®žECGã€çœŸå®žæ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾ç»˜åˆ¶åœ¨ä¸€èµ·ã€‚
    """
    import numpy as np

    model.eval()
    
    batch = next(iter(dataloader))
    mmwave_input = batch['radar'].to(device).transpose(1, 2)
    ecg_true = batch['ecg'].cpu().numpy()
    ce_labels_true = batch['ce_labels'].cpu().numpy()

    with torch.no_grad():
        ce_labels_pred = model(mmwave_input).cpu().numpy()
    
    actual_samples = min(num_samples, mmwave_input.size(0))
    fig, axes = plt.subplots(actual_samples, 1, figsize=(15, 3 * actual_samples), squeeze=False)
    fig.suptitle(f'CE Prediction - Epoch {epoch}', fontsize=16)

    event_names = ['P', 'Q', 'R', 'S', 'T']
    event_colors = ['green', 'orange', 'red', 'purple', 'brown']

    for i in range(actual_samples):
        ax = axes[i, 0]
        # 1. ç»˜åˆ¶çœŸå®žçš„ECGæ³¢å½¢ä½œä¸ºèƒŒæ™¯å‚è€ƒ
        ax.plot(ecg_true[i, 0, :], color='gray', alpha=0.5, label='Ground Truth ECG')
        
        # 2. ç»˜åˆ¶çœŸå®žæ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
        for j in range(5): # éåŽ†P,Q,R,S,T
            # æ‰¾åˆ°çœŸå®žæ ‡ç­¾çš„ä½ç½®ï¼ˆå€¼ä¸º1çš„åœ°æ–¹ï¼‰
            true_peaks = np.where(ce_labels_true[i, j, :] == 1)[0]
            if len(true_peaks) > 0:
                ax.vlines(true_peaks, ymin=0.8, ymax=1.0, color=event_colors[j], linestyle='-', label=f'True {event_names[j]}')

            # ç»˜åˆ¶é¢„æµ‹å€¼ï¼ˆä½œä¸ºä¸€ä¸ªè¿žç»­çš„æ¦‚çŽ‡æ›²çº¿ï¼‰
            ax.plot(ce_labels_pred[i, j, :], color=event_colors[j], linestyle='--', label=f'Predicted {event_names[j]}')

        ax.set_title(f'Sample {i+1}')
        ax.legend(loc='upper right')
        ax.set_xlabel('Time Steps')
        ax.set_ylabel('Amplitude / Probability')
        ax.set_ylim(-1.1, 1.1) # è®¾å®šYè½´èŒƒå›´ä»¥ä¾¿è§‚å¯Ÿ

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    model.train()
    
    return fig